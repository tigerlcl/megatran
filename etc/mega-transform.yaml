# basic config
n_shot: 3
code_attempt: 3
prompt_mode: "chat_example" # for chat_to_inst
exp_folder: "revision" # exp
# prompt_mode: "code_example" # for code generation OR chat_to_inst = false

# MegaTransform control, turn on/off modules
chat_to_inst: true
allow_reflection: true
allow_rag: true

# OPENAI chat model (shared in code generator and reflection)
openai_model: "gpt-4o-mini" # gpt-4o, gpt-4o-mini
openai_temperature: 0.2

# OPENAI embedding model
embedding_model: "text-embedding-3-small" 

# Chat2Inst backend (online)
vllm_model: "./assets/models/llama3_lora_sft"
vllm_temperature: 0.2
vllm_cfg:
  base_url: "http://localhost:8000/v1"
  api_key: "token-abc123"

# Lazy RAG (online)
pkg_info_path: "./assets/rag/pkg_info.json"
vec_db_dir: "./assets/rag/code_db_v2"
