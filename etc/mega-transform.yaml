# basic config
n_shot: 3
code_attempt: 3
prompt_mode: "chat_example" # Can use chat, ctx, example as keywords to control the prompt

# Framework control, turn on/off modules
chat_to_inst: true
allow_reflection: true
allow_rag: true

# OPENAI chat model (shared in code generator and reflection)
openai_model: "gpt-4o" # gpt-4o, gpt-4o-mini
openai_temperature: 0.2

# OPENAI embedding model
embedding_model: "text-embedding-3-small" 

# Chat2Inst backend (online)
vllm_model: "./assets/models/llama3_lora_sft"
vllm_temperature: 0.2
vllm_cfg:
  base_url: "http://localhost:8000/v1"
  api_key: "token-abc123"

# Lazy RAG (online)
pkg_info_path: "./assets/rag/pkg_info.json"
vec_db_dir: "./assets/rag/code_db"
